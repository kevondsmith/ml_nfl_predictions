{"cells":[{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Final shape = (534, 8)\n","\n","Random Forest Mean squared error: 236.98\n","Random Forest Variance score: -0.09\n","\n","Best test score for k= 5 is:  [-0.0883467552602688] \n","\n","\n","Random Forest Mean squared error: 258.49\n","Random Forest Variance score: -0.19\n","\n","Best test score for k= 10 is:  [-0.0883467552602688, -0.18713814612696922] \n","\n","\n","Random Forest Mean squared error: 262.26\n","Random Forest Variance score: -0.20\n","\n","Best test score for k= 15 is:  [-0.0883467552602688, -0.18713814612696922, -0.204414886458949] \n","\n","\n","\n","Random Forest depth sweep results:\n","Depths:\n","[5, 10, 15]\n","MSES:\n","[236.98220872705994, 258.49355324814525, 262.25547936561446]\n","R2S:\n","[-0.0883467552602688, -0.18713814612696922, -0.204414886458949]\n","\n","Random Forest Mean squared error: 233.81\n","Random Forest Variance score: -0.07\n","\n","\n","Random Forest Mean squared error: 237.03\n","Random Forest Variance score: -0.09\n","\n","\n","Random Forest Mean squared error: 236.98\n","Random Forest Variance score: -0.09\n","\n","\n","Random Forest Mean squared error: 236.21\n","Random Forest Variance score: -0.08\n","\n","Random Forest ntrees sweep results:\n","ntrees:\n","[10, 20, 50, 100]\n","MSES:\n","[233.80975051737843, 237.0251299561195, 236.98220872705994, 236.21150970635577]\n","R2S:\n","[-0.07377716112384869, -0.08854387208447978, -0.0883467552602688, -0.08480730061947028]\n"]}],"source":["import numpy as np,os,matplotlib.pyplot as plt,warnings\n","import pandas as pd\n","import statsmodels.api as sm\n","from sklearn import linear_model, neural_network\n","from sklearn import model_selection, metrics\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.multioutput import MultiOutputRegressor\n","\n","\n","# Get data\n","dataset = pd.read_csv(\"~/CSCE 822 - Data Mining and Warehousing/Project/ml_nfl_predictions/data/schedules/2007-2008_games_schedules.csv\")\n","# print(dataset.shape)\n","\n","# May need to impute data\n","dataset = dataset[(dataset[dataset.columns] != \"--\").all(axis=1)]\n","\n","# Remove all string features\n","dataset = dataset.loc[:, dataset.dtypes != str]\n","# print(dataset.shape)\n","\n","# Try forcing to numeric\n","dataset = dataset.apply(lambda row: pd.to_numeric(row, errors='coerce', downcast='float'))\n","g = dataset.columns.to_series().groupby(dataset.dtypes).groups\n","# print(g)\n","\n","# Remove all columns with NAs\n","dataset = dataset.dropna(axis = 1)\n","\n","# Remove all columns that are not numeric\n","dataset = dataset._get_numeric_data()\n","print(\"Final shape = \" + str(dataset.shape))\n","print(\"\")\n","\n","# Label cols\n","label = \"result\"\n","label_cols = ['away_team', 'away_score', 'home_team', 'home_score', 'result']\n","\n","\n","# Train/test split\n","X_train, X_test, y_train, y_test = model_selection.train_test_split(data, labels, test_size=0.20, random_state=42) # 20% test\n","X_train, X_val, y_train, y_val = model_selection.train_test_split(X_train, y_train, test_size=0.25, random_state=42) # 20% val, 60% train\n","\n","# Sweep found best max depth = 10\n","depths = [5, 10, 15]\n","mses = []\n","r2s = []\n","for depth in depths:\n","\t# Try random forests\n","\tregr = RandomForestRegressor(n_estimators=50, max_depth=depth,\n","\t                                random_state=2)\n","\tregr.fit(X_train, y_train)\n","\t# Make predictions using the testing set\n","\ty_pred = regr.predict(X_val)\n","\t# The mean squared error\n","\tprint(\"Random Forest Mean squared error: %.2f\"\n","\t      % metrics.mean_squared_error(y_val, y_pred))\n","\tmses.append(metrics.mean_squared_error(y_val, y_pred))\n","\t# Explained variance score: 1 is perfect prediction\n","\tprint('Random Forest Variance score: %.2f' % metrics.r2_score(y_val, y_pred))\n","\tprint(\"\")\n","\tr2s.append(metrics.r2_score(y_val, y_pred))\n","\tprint(\"Best test score for k=\", depth, \"is: \", r2s, '\\n'*2)\n","\n","print(\"\")\n","print(\"Random Forest depth sweep results:\")\n","\n","print('Depths:')\n","print(depths)\n","print('MSES:')\n","print(mses)\n","print('R2S:')\n","print(r2s)\n","\n","\n","# Sweep over num trees\n","ntrees = [10, 20, 50, 100]\n","mses = []\n","r2s = []\n","for ntree in ntrees:\n","\t# Try random forests\n","\tregr = RandomForestRegressor(n_estimators=ntree, max_depth=5,\n","\t                                random_state=2)\n","\tregr.fit(X_train, y_train)\n","\t# Make predictions using the testing set\n","\ty_pred = regr.predict(X_val)\n","\t# The mean squared error\n","\tprint(\"\")\n","\tprint(\"Random Forest Mean squared error: %.2f\"\n","\t      % metrics.mean_squared_error(y_val, y_pred))\n","\tmses.append(metrics.mean_squared_error(y_val, y_pred))\n","\t# Explained variance score: 1 is perfect prediction\n","\tprint('Random Forest Variance score: %.2f' % metrics.r2_score(y_val, y_pred))\n","\tprint(\"\")\n","\tr2s.append(metrics.r2_score(y_val, y_pred))\n","\n","print(\"Random Forest ntrees sweep results:\")\n","print('ntrees:')\n","print(ntrees)\n","print('MSES:')\n","print(mses)\n","print('R2S:')\n","print(r2s)"]}],"metadata":{"interpreter":{"hash":"01c1cefed0550c79a29fba90c54ae81dac69522dafa1a36afb5a68ec6c0cf5be"},"kernelspec":{"display_name":"Python 3.9.7 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
